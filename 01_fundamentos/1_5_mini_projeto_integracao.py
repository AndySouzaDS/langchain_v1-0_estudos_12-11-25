from langchain.chat_models import init_chat_model
from dotenv import load_dotenv
import time

# carregar api keys
load_dotenv()

# configuraÃ§Ãµes personalizadas
PERSONALIDADES = {
    "1": {
        "nome": "Professor Paciente",
        "prompt": "VocÃª Ã© um professor paciente que explica conceitos de LangChain de forma didÃ¡tica, com exemplos e analogias."
    },
    "2": {
        "nome": "Dev SÃªnior",
        "prompt": "VocÃª Ã© um desenvolvedor sÃªnior experiente. Respostas diretas, cÃ³digo limpo, sem enrolaÃ§Ã£o."
    },
    "3": {
        "nome": "DocumentaÃ§Ã£o Viva",
        "prompt": "VocÃª responde no estilo da documentaÃ§Ã£o oficial: estruturado, com parÃ¢metros, exemplos e links quando relevante."
    }
}

def setup_model():
    """Inicializa o modelo Groq"""
    return init_chat_model("groq:llama-3.3-70b-versatile")

def get_system_prompt(escolha):
    """Retorna o system prompt baseado na personalidade escolhida."""
    return {
        "role": "system",
        "content": PERSONALIDADES[escolha]["prompt"]
    }

def print_menu():
    """Mostra o menu de personalidades."""
    print("\nðŸŽ­ Escolha a personalidade do assistente:")
    for key, value in PERSONALIDADES.items():
        print(f"{key}. {value['nome']}")
    print()

def handle_command(comando, messages, stats):
    """Processa comandos especiais."""
    if comando == "/trocar":
        print_menu()  # mostrarÃ¡ novamente as opÃ§Ãµes de personalidades
        nova_escolha = input("Escolha (1-3): ")
        if nova_escolha in PERSONALIDADES:
            # substituiÃ§Ã£o system message
            messages[0] = get_system_prompt(nova_escolha)
            print(f"âœ… Personalidade trocada para: {PERSONALIDADES[nova_escolha]['nome']}\n")
        return True
    
    elif comando == "/historico":
        print("\nðŸ“œ Ãšltimas 5 mensagens:")
        for msg in messages[-10:]:  # Ãºltimas 5 trocas (10 msgs)
            if msg["role"] != "system":
                role_emoji = "ðŸ‘¤" if msg["role"] == "user" else "ðŸ¤–"
                print(f"{role_emoji} {msg['content'][:80]}...")
        print()
        return True
    
    elif comando == "/limpar":
        # mantÃ©m apenas system message
        system_msg = messages[0]
        messages.clear()
        messages.append(system_msg)
        stats["mensagens"] = 0
        print("âœ… Conversa resetada!\n")
        return True
    
    elif comando == "/sair":
        return False
    
    return True

def display_stats(stats, tempo_resposta):
    """Mostra estatÃ­sticas da conversa."""
    stats["tempo_total"] += tempo_resposta
    print(f"\nðŸ“Š Mensagens: {stats['mensagens']} | Tempo resposta: {tempo_resposta:.2f}s | Total: {stats['tempo_total']:.2f}s")
    print("-" * 70 + "\n")

def chat_loop():
    """Loop principal do chat."""
    # setup
    model = setup_model()

    # escolher personalidade inicial
    print("ðŸš€ Assistente TÃ©cnico LangChain v1.0")
    print_menu()
    escolha = input("Escolha inicial (1-3): ")

    if escolha not in PERSONALIDADES:
        escolha = "1"

    # inicializar histÃ³rico com system prompt
    messages = [get_system_prompt(escolha)]
   
    # estatÃ­sticas
    stats = {"mensagens": 0, "tempo_total": 0}

    print(f"\nâœ… Assistente ativo: {PERSONALIDADES[escolha]['nome']}")
    print("\nComandos: /trocar | /historico | /limpar | /sair\n")

    # loop principal
    while True:
        # input do usuÃ¡rio
        user_input = input("VocÃª: ").strip()
    
        if not user_input:
            continue
        
        # verificar se Ã© comando
        if user_input.startswith("/"):
            continuar = handle_command(user_input, messages, stats)
            if not continuar:
                print(f"\nðŸ‘‹ Encerrando. Total de mensagens: {stats['mensagens']}")
                break
            continue
        
        # adicionar mensagem do usuÃ¡rio
        messages.append(
            {
                "role": "user",
                "content": user_input
            }
        )
    
        # invocar modelo e medir tempo
        inicio = time.time()
        response = model.invoke(messages)
        tempo_resposta = time.time() - inicio
    
        # adicionar resposta ao histÃ³rico
        messages.append(
            {
                "role": "assistant",
                "content": response.content
            }
        )
    
        # atualizar stats
        stats["mensagens"] += 1
    
        # mostrar resposta
        print(f"\nðŸ¤– {PERSONALIDADES[escolha]['nome']}:")
        print(response.content)
    
        # mostrar stats
        display_stats(stats, tempo_resposta)

# executar
if __name__ == "__main__":
    chat_loop()
    
